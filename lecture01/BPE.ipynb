{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70dc0563",
   "metadata": {},
   "source": [
    "## Byte Pair Encoding (BPE)\n",
    "\n",
    "这里给出一个ASCII-level的BPE实现, 在实际引用中, 通常用byte-level的, 即字符UTF-8的比特位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d084978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BPE Codes ===\n",
      "('l', 'o')\n",
      "('lo', 'w')\n",
      "('e', 's')\n",
      "('es', 't')\n",
      "('est', '</w>')\n",
      "('low', '</w>')\n",
      "('low', 'e')\n",
      "('lowe', 'r')\n",
      "('lower', '</w>')\n",
      "('n', 'e')\n",
      "\n",
      "=== Encoding ===\n",
      "[['low', 'est</w>'], ['ne', 'w', 'est</w>']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class BPETokenizer:\n",
    "    def __init__(self, vocab_size=100):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.bpe_codes = {}\n",
    "        self.vocab = {}\n",
    "\n",
    "    def get_vocab(self, corpus):\n",
    "        \"\"\"将语料转换为初始词汇表（字符级）\"\"\"\n",
    "        vocab = defaultdict(int)\n",
    "        for word in corpus:\n",
    "            word = word.strip()\n",
    "            # 将词分解为字符，并添加结束符标记（便于区分词边界）\n",
    "            chars = \" \".join(list(word)) + \" </w>\"\n",
    "            vocab[chars] += 1\n",
    "        return vocab\n",
    "\n",
    "    def get_stats(self, vocab):\n",
    "        \"\"\"统计所有token对的频率\"\"\"\n",
    "        pairs = defaultdict(int)\n",
    "        for word, freq in vocab.items():\n",
    "            symbols = word.split()\n",
    "            for i in range(len(symbols) - 1):\n",
    "                pairs[(symbols[i], symbols[i + 1])] += freq\n",
    "        return pairs\n",
    "\n",
    "    def merge_vocab(self, pair, vocab):\n",
    "        \"\"\"合并给定的字符对\"\"\"\n",
    "        new_vocab = {}\n",
    "        pattern = re.escape(\" \".join(pair))\n",
    "        replacement = \"\".join(pair)\n",
    "        re_pattern = re.compile(r\"(?<!\\S)\" + pattern + r\"(?!\\S)\")\n",
    "        for word in vocab:\n",
    "            new_word = re_pattern.sub(replacement, word)\n",
    "            new_vocab[new_word] = vocab[word]\n",
    "        return new_vocab\n",
    "\n",
    "    def train(self, corpus):\n",
    "        self.vocab = self.get_vocab(corpus)\n",
    "        for i in range(self.vocab_size):\n",
    "            pairs = self.get_stats(self.vocab)\n",
    "            if not pairs:\n",
    "                break\n",
    "            best = max(pairs, key=pairs.get)\n",
    "            self.bpe_codes[best] = i\n",
    "            self.vocab = self.merge_vocab(best, self.vocab)\n",
    "\n",
    "    def encode_word(self, word):\n",
    "        \"\"\"对单个词进行 BPE 编码\"\"\"\n",
    "        word = list(word) + ['</w>']\n",
    "        while True:\n",
    "            pairs = [(word[i], word[i+1]) for i in range(len(word)-1)]\n",
    "            bpe_pairs = {pair: self.bpe_codes.get(pair, float('inf')) for pair in pairs}\n",
    "            if not bpe_pairs:\n",
    "                break\n",
    "            best_pair = min(bpe_pairs, key=bpe_pairs.get)\n",
    "            if bpe_pairs[best_pair] == float('inf'):\n",
    "                break\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                if i < len(word)-1 and (word[i], word[i+1]) == best_pair:\n",
    "                    new_word.append(word[i] + word[i+1])\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            word = new_word\n",
    "        return word\n",
    "\n",
    "    def encode(self, sentence):\n",
    "        \"\"\"对句子进行编码\"\"\"\n",
    "        return [self.encode_word(word) for word in sentence.split()]\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == \"__main__\":\n",
    "    corpus = [\n",
    "        \"low\", \"lower\", \"newest\", \"widest\"\n",
    "    ]\n",
    "    tokenizer = BPETokenizer(vocab_size=10)\n",
    "    tokenizer.train(corpus)\n",
    "\n",
    "    print(\"=== BPE Codes ===\")\n",
    "    for k, v in tokenizer.bpe_codes.items():\n",
    "        print(k)\n",
    "\n",
    "    print(\"\\n=== Encoding ===\")\n",
    "    print(tokenizer.encode(\"lowest newest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568bad2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
