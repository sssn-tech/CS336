{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08014e76",
   "metadata": {},
   "source": [
    "# lecture01课程笔记\n",
    "课程讲义: https://stanford-cs336.github.io/spring2025-lectures/?trace=var/traces/lecture_01.json\n",
    "\n",
    "第一节课的干货不算很多, 主要聊聊天, 介绍下课程的主要内容等\n",
    "\n",
    "#### 为什么要制作这门课程(CS336)\n",
    "\n",
    "Researchers对语言模型底层原理的理解变浅了, 大家都喜欢让AI完成基础任务. 这在一些情况下是合理的, 但是也带来了问题:\n",
    "- 我们不了解AI具体在做什么, 只能看到效果\n",
    "- 语言模型的基础研究依旧重要\n",
    "\n",
    "#### 通过这门课程, 我们可以学到什么\n",
    "\n",
    "- 语言模型的基本原理(Transformer, tokenizer, optimizer, GPU并行化等)\n",
    "- 开展语言模型研究的思维模式(scaling laws等)\n",
    "- 对语言模型相关研究的直觉(什么是好模型, 什么是好数据)\n",
    "\n",
    "#### 重要认知: 算法依旧重要\n",
    "学界已经有相当多研究模型参数量, 训练充分性的研究. 一些人认为模型参数量占决定性作用, 这不对\n",
    "\n",
    "准确率 = 效率 x 资源\n",
    "\n",
    "#### Assignments\n",
    "课程准备了5次assignments\n",
    "- 基本概念: 最难的是第一次\n",
    "- 系统\n",
    "- scaling laws\n",
    "- 数据\n",
    "- 对齐\n",
    "\n",
    "这对应课程的5个部分\n",
    "![alt text](https://stanford-cs336.github.io/spring2025-lectures/images/design-decisions.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9527d9b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
